{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overview of this approach is I want to use log reg to get probability functions for each class (ie odds that data point is that class). Since 1/(1+e^{-t}) is increasing and I can get back the coeffs for determining t, we'll use whatever t value is the highest to pick the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EpcProject2.csv')\n",
    "#Get rid of hexidecimals\n",
    "df = df.apply(lambda x: [int(i, 16) for i in x] if x.name in '1236' else x)\n",
    "df.replace({'A':10, 'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16}, inplace=True)\n",
    "\n",
    "df['Checkers'] = df['1'] + df['2'] + df['3'] + df['4'] + df['5'] + df['6']\n",
    "\n",
    "\n",
    "df_high = df.loc[df['Description']=='High']\n",
    "df_med = df.loc[df['Description']=='Medium']\n",
    "df_low = df.loc[df['Description']=='Low']\n",
    "df_rol = df.loc[df['Description']=='Rollish']\n",
    "\n",
    "\n",
    "df['Men off']= df['Men off'].astype(int)\n",
    "df['Odd']= (df['Checkers']%2==1).astype(int)\n",
    "df['CG'] = (df['PC']/df['Checkers'] - df['Odd']/2)\n",
    "df['CG_N']= (df['CG']/df['CG'].max())*2\n",
    "df['gap1']= (df['1']==0).astype(int)\n",
    "df['gap2']= (df['2']==0).astype(int)\n",
    "df['gap3']= (df['3']==0).astype(int)\n",
    "df['gap4']= (df['4']==0).astype(int)\n",
    "df['gap5']= (df['5']==0).astype(int)\n",
    "df['gap6']= (df['6']==0).astype(int)\n",
    "\n",
    "\n",
    "df['tower1'] = (df['1'] >= 5).astype(int)\n",
    "df['tower2'] = (df['2'] >= 5).astype(int)\n",
    "df['tower3'] = (df['3'] >= 5).astype(int)\n",
    "df['tower4'] = (df['4'] >= 5).astype(int)\n",
    "df['tower5'] = (df['5'] >= 5).astype(int)\n",
    "df['tower6'] = (df['6'] >= 5).astype(int)\n",
    "df['towers'] = df['tower1'] + df['tower2'] + df['tower3'] + df['tower4'] + df['tower5'] + df['tower6']\n",
    "\n",
    "df['acedeuce'] = (df['1']+df['2'])\n",
    "df['highlow'] = df[['6', '5', '4', '3', '2', '1']].max(axis=1) - df[['6', '5', '4', '3', '2', '1']].min(axis=1)\n",
    "\n",
    "df['High'] = df['Description'] == 'High'\n",
    "df['Medium'] = df['Description'] == 'Medium'\n",
    "df['Low'] = df['Description'] == 'Low'\n",
    "df['Rollish'] = df['Description'] == 'Rollish'\n",
    "\n",
    "\n",
    "# df = df.loc[df['Checkers'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "'Odd',\n",
    "'gap1',\n",
    "'gap2',\n",
    "'gap3',\n",
    "'gap4',\n",
    "'gap5',\n",
    "'gap6',\n",
    "'highlow', \n",
    "'Checkers',\n",
    "'1',\n",
    "'2',\n",
    "'3',\n",
    "'4',\n",
    "'5',\n",
    "'6', \n",
    "'PC']\n",
    "std_scalar = StandardScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[columns] = std_scalar.fit_transform(df_scaled[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for the params to use we're gonna scale the data set and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[columns]\n",
    "y_h = df_scaled['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.018271762311709603, 0.38278351385824244, 0.19410986301373817, -0.03920361422904829, -0.07283608036083083, 0.18434412227159475, 0.14794147569509378, 0.2746864536689803, -0.14907138944061055, -0.10483658396653275, -0.19057776895188935, -0.24100782231843712, 0.0, 0.5019781948262501, 0.314155430638792, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.38278351385824244, 1), (0.5019781948262501, 13)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=False)\n",
    "model_h.fit(X,y_h)\n",
    "model_h.score(X,y_h)\n",
    "print(model_h.coef_.tolist()[0])\n",
    "\n",
    "attributes = [(-10000,0), (-10000,0)]\n",
    "for i, coef in enumerate(model_h.coef_.tolist()[0]):\n",
    "    if abs(coef) >= max(attributes)[0]:\n",
    "        attributes.remove(min(attributes))\n",
    "        attributes.append((coef, i))\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['acedeuce', '3']]\n",
    "y_h = df['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.17605778 -0.99015307]]\n",
      "[3.1934854]\n",
      "0.9359005605654399\n"
     ]
    }
   ],
   "source": [
    "model_h = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_h.fit(X,y_h)\n",
    "model_h.score(X,y_h)\n",
    "print(model_h.coef_)\n",
    "print(model_h.intercept_)\n",
    "print(model_h.score(X,y_h))\n",
    "# coeffs = model_h.coef_.tolist()[0]\n",
    "# for i,ele in enumerate(coeffs):\n",
    "#     coeffs[i] = abs(ele)\n",
    "# print(coeffs)\n",
    "# print(coeffs.index(max(coeffs)))\n",
    "# columns[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[columns]\n",
    "y_m = df_scaled['Medium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45847717 -0.73342765 -0.23704084  0.20588325  0.21501029 -0.13082777\n",
      "  -0.03680957  0.45680618  0.05033837  0.01605361 -0.01343911 -0.25287093\n",
      "  -0.23080992  0.         -0.91506137  0.10565572 -0.07319697 -1.11521008\n",
      "   0.          0.22597834  0.17072743 -0.04750196  0.          0.\n",
      "   0.00451842]]\n",
      "0.7354322490867977\n"
     ]
    }
   ],
   "source": [
    "model_m = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_m.fit(X,y_m)\n",
    "print(model_m.coef_)\n",
    "print(model_m.score(X,y_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_l = df['Low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785701861193251"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['CG', 'acedeuce', 'Odd']]\n",
    "model_l = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_l.fit(X,y_l)\n",
    "model_l.score(X,y_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the dataset to lmk whats actually useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[columns]\n",
    "y_r = df_scaled['Rollish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.42905658 -1.14092589 -0.76683569 -0.86653628 -0.95030125 -0.4753547\n",
      "  -0.06133433 -2.24630132  0.          3.46826529  2.2332344   0.59538461\n",
      "  -0.60758646 -2.03960065 -3.80347393 -2.04456007]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_r.fit(X,y_r)\n",
    "model_r.score(X,y_r)\n",
    "print(model_r.coef_)\n",
    "columns[14]\n",
    "columns[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.4682652899657556, 9), (-3.8034739318002875, 14)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = [(-10000,0), (-10000,0)]\n",
    "for i, coef in enumerate(model_r.coef_.tolist()[0]):\n",
    "    if abs(coef) >= max(attributes)[0]:\n",
    "        attributes.remove(min(attributes))\n",
    "        attributes.append((coef, i))\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['acedeuce', 'PC']]\n",
    "y_r = df['Rollish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771960340928857\n",
      "[[ 0.63148222 -0.11473601]]\n",
      "[-1.42629729]\n"
     ]
    }
   ],
   "source": [
    "model_r = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_r.fit(X,y_r)\n",
    "print(model_r.score(X,y_r))\n",
    "print(model_r.coef_)\n",
    "print(model_r.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no idea if a more compact form will be more useful for testing so im adding it\n",
    "X = df[['PC', 'Men off', 'Odd']]\n",
    "y_h = df['High']\n",
    "y_m = df['Medium']\n",
    "y_l = df['Low']\n",
    "y_r= df['Rollish']\n",
    "\n",
    "model_h = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "model_h.fit(X,y_h)\n",
    "\n",
    "model_m = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "model_m.fit(X,y_m)\n",
    "\n",
    "model_l = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "model_l.fit(X,y_l)\n",
    "\n",
    "model_r = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "model_r.fit(X,y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, models:list, round_deg = 64):\n",
    "        self.models = models\n",
    "        self.round_deg = round_deg\n",
    "        self.decisions = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            decision = model.decision_function(X)\n",
    "            self.decisions.append((decision,i)) #to make sure we know what model is doing the scoring\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for i in range(len((X))):\n",
    "            max_score = (-10000000, 0)\n",
    "            for decision in self.decisions:\n",
    "                score = (decision[0][i], decision[1])\n",
    "                max_score = max(max_score, score)\n",
    "            if max_score[1] == 0:\n",
    "                y_pred.append('High')\n",
    "            if max_score[1] == 1:\n",
    "                y_pred.append('Medium')\n",
    "            if max_score[1] == 2:\n",
    "                y_pred.append('Low')\n",
    "            if max_score[1] == 3:\n",
    "                y_pred.append('Rollish')\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([model_h, model_m, model_l, model_r])\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6742042094277265"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['Description'],y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f3d05cfa189ae7dba9a0c2af59696e6bfd9fa90cf4658823dc0ff8a549075f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
